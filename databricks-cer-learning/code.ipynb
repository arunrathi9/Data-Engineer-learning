{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "# sql \n",
    "describe history tableName -- to see the table history\n",
    "\n",
    "describe extended tableName # to get the table statistics\n",
    "describe tableName # table basic details\n",
    "\n",
    "# load data incrementally\n",
    "COPY INTO # cmd \n",
    "\n",
    "DROP TABLE IF EXISTS tableName\n",
    "CREATE TABLE tableName USING DELTA;\n",
    "\n",
    "COPY INTO tableName\n",
    "FROM '${DA.paths.datasets}/ecommerce/raw/users'\n",
    "FILEFORMAT = parquet\n",
    "COPY_OPTIONS ('mergeSchema'='true');\n",
    "\n",
    "\n",
    "# external storage\n",
    "# using LOCATION keyword\n",
    "\n",
    "\n",
    "## Basic transformations\n",
    "\n",
    "-- 1. Clone of Delta tables:\n",
    "    -- a. Deep Clone - data and metadata from source table to target\n",
    "    CREATE or REPLACE table tableName\n",
    "    DEEP CLONE [SHALLOW CLONE] tableName\n",
    "    -- b. Shallow Clone - just copy delta transaction logs, data doesn't move\n",
    "    # **In either case, data modifications applied to cloned version of the table\n",
    "    # will be tracked and stored separately from the source. Cloning is a great way\n",
    "    # to set up tables for testing SQL code while still in development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image1](images/m1-over.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Merge updates:\n",
    "    -- Delta lake supports inserts, updates and deletes in merge statement and supports extended \n",
    "    -- syntax beyoud sql standards for advanced use cases\n",
    "\n",
    "MERGE INTO target a\n",
    "using source b\n",
    "on {merge.condition}\n",
    "WHEN MATCHED THEN {matched_action}\n",
    "WHEN NOT MATCHED THEN {not_matched_action}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image2](images/m1-merge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**setting below config to allow generating columns in merge statement**\n",
    "\n",
    "set spark.databricks.delta.schema.autoMerge.enabled=true;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**\n",
    "\n",
    "Remove duplicate rows:\n",
    "    * SQL syntax: Insert overwrite targettablename select distinct(*) from sourcetable;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
